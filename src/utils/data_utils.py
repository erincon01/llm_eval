import os

import pandas as pd

from utils.dataframe_utils import align_columns_by_first_row, normalize_numeric_columns


class DataUtils:
    """
    Utility class for data operations.
    Extracted from LLMsEvaluator.compare_baseline_resultset_with_LLM_resultset()
    """

    @staticmethod
    def compare_dataframes(baseline_df, llm_df, question_number):
        """
        Compares the baseline resultset with the one generated by the LLM,
        ignoring column names and order, but considering the internal
        order of values in each row.

        :param baseline_df: Baseline DataFrame.
        :param llm_df: DataFrame generated by the LLM.
        :param question_number: Question number.
        :return:
            - percent_rows_equality: ratio of number of rows (size-based)
            - percent_columns_equality: ratio of number of columns (size-based)
            - percent_baseline_covered: how much of baseline data is covered
                in LLM result
            - percent_llm_covered: how much of LLM data exists in baseline
        """
        if baseline_df is None or llm_df is None or baseline_df.empty:
            return 0.00, 0.00, 0.00, 0.00

        try:
            # Normalize numeric columns to avoid float/decimal mismatches
            baseline_df, llm_df = normalize_numeric_columns(baseline_df, llm_df)

            # Align columns based on values in the first row (not column names)
            baseline_df, llm_df = align_columns_by_first_row(baseline_df, llm_df)

            # Convert rows to sets of tuples for set comparison
            baseline_set = set(map(tuple, baseline_df.to_numpy()))
            llm_set = set(map(tuple, llm_df.to_numpy()))

            # Calculate intersection
            intersection = baseline_set.intersection(llm_set)

            # Coverage percentages
            percent_baseline_covered = round(len(intersection) / len(baseline_set), 2) if baseline_set else 0.0
            percent_llm_covered = round(len(intersection) / len(llm_set), 2) if llm_set else 0.0

            # Pure size comparison (not content-aware)
            percent_rows_equality = round(len(llm_df) / len(baseline_df), 2) if len(llm_df) <= len(baseline_df) else 0.0
            percent_columns_equality = (
                round(len(llm_df.columns) / len(baseline_df.columns), 2)
                if len(llm_df.columns) <= len(baseline_df.columns)
                else 0.0
            )

            return (
                percent_rows_equality,
                percent_columns_equality,
                percent_baseline_covered,
                percent_llm_covered,
            )

        except Exception as e:
            print(f"[ERROR] Question #{question_number}: comparison failed: {e}")
            return 0.0, 0.0, 0.0, 0.0

    @staticmethod
    def load_baseline_datasets(baseline_path: str):
        """
        Loads baseline datasets from the specified directory path.

        This method searches for CSV files in the given directory whose
        filenames start with "question_" and end with ".csv".
        Each matching file is read into a pandas DataFrame, and the question number is
        extracted from the filename.

        Args:
            baseline_path (str): The path to the directory containing baseline dataset CSV files.

        Returns:
            list: List of dictionaries with question_number and df keys

        Raises:
            FileNotFoundError: If the specified baseline_path does not exist.
            NotADirectoryError: If the specified baseline_path is not a directory.
        """
        try:
            if not os.path.exists(baseline_path):
                raise FileNotFoundError(f"Baseline path {baseline_path} does not exist.")
            if not os.path.isdir(baseline_path):
                raise NotADirectoryError(f"Baseline path {baseline_path} is not a directory.")
        except Exception as e:
            print(f"Error loading baseline datasets: {e}")
            return []

        baseline_datasets = []

        for file in os.listdir(baseline_path):
            file_path = os.path.join(baseline_path, file)
            if os.path.isfile(file_path) and file.startswith("question_") and file.endswith(".csv"):
                df = pd.read_csv(file_path, sep="\t", encoding="utf-8")
                question_number = int(file.split("_")[1].split(".")[0])
                baseline_datasets.append({"question_number": question_number, "df": df})

        return baseline_datasets
